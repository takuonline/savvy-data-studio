# Generated by Django 4.2.20 on 2025-04-28 00:37

from django.conf import settings
from django.db import migrations, models
import django.db.models.deletion
import node_graph.models.node_graph
import uuid


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='ChatOpenAI',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('cache', models.BooleanField(blank=True, help_text='Whether to cache the response.', null=True)),
                ('callback_manager', models.JSONField(blank=True, help_text='Callback manager to add to the run trace.', null=True)),
                ('callbacks', models.JSONField(blank=True, help_text='Callbacks to add to the run trace.', null=True)),
                ('default_headers', models.JSONField(blank=True, help_text='Default headers for HTTP requests.', null=True)),
                ('default_query', models.JSONField(blank=True, help_text='Default query parameters for HTTP requests.', null=True)),
                ('http_client', models.TextField(blank=True, help_text='Optional httpx.Client.', null=True)),
                ('max_retries', models.IntegerField(default=6, help_text='Maximum number of retries to make when generating.')),
                ('max_tokens', models.IntegerField(blank=True, help_text='Maximum number of tokens to generate.', null=True)),
                ('metadata', models.JSONField(blank=True, help_text='Metadata to add to the run trace.', null=True)),
                ('model_kwargs', models.JSONField(blank=True, default=dict, help_text='Holds any model parameters valid for create call not explicitly specified.', null=True)),
                ('model_name', models.CharField(blank=True, choices=[('text-search-babbage-doc-001', 'text-search-babbage-doc-001'), ('gpt-4-vision-preview', 'gpt-4-vision-preview'), ('curie-search-query', 'curie-search-query'), ('text-search-babbage-query-001', 'text-search-babbage-query-001'), ('babbage', 'babbage'), ('babbage-search-query', 'babbage-search-query'), ('text-babbage-001', 'text-babbage-001'), ('text-similarity-davinci-001', 'text-similarity-davinci-001'), ('davinci-similarity', 'davinci-similarity'), ('code-davinci-edit-001', 'code-davinci-edit-001'), ('curie-similarity', 'curie-similarity'), ('babbage-search-document', 'babbage-search-document'), ('curie-instruct-beta', 'curie-instruct-beta'), ('text-search-ada-doc-001', 'text-search-ada-doc-001'), ('davinci-instruct-beta', 'davinci-instruct-beta'), ('text-similarity-babbage-001', 'text-similarity-babbage-001'), ('text-search-davinci-doc-001', 'text-search-davinci-doc-001'), ('gpt-4-0314', 'gpt-4-0314'), ('babbage-similarity', 'babbage-similarity'), ('text-embedding-ada-002', 'text-embedding-ada-002'), ('davinci-search-query', 'davinci-search-query'), ('text-similarity-curie-001', 'text-similarity-curie-001'), ('gpt-4', 'gpt-4'), ('text-davinci-001', 'text-davinci-001'), ('text-search-davinci-query-001', 'text-search-davinci-query-001'), ('ada-search-document', 'ada-search-document'), ('ada-code-search-code', 'ada-code-search-code'), ('babbage-002', 'babbage-002'), ('davinci-002', 'davinci-002'), ('davinci-search-document', 'davinci-search-document'), ('curie-search-document', 'curie-search-document'), ('babbage-code-search-code', 'babbage-code-search-code'), ('text-search-ada-query-001', 'text-search-ada-query-001'), ('code-search-ada-text-001', 'code-search-ada-text-001'), ('babbage-code-search-text', 'babbage-code-search-text'), ('code-search-babbage-code-001', 'code-search-babbage-code-001'), ('ada-search-query', 'ada-search-query'), ('gpt-4-1106-preview', 'gpt-4-1106-preview'), ('ada-code-search-text', 'ada-code-search-text'), ('tts-1-hd', 'tts-1-hd'), ('text-search-curie-query-001', 'text-search-curie-query-001'), ('text-davinci-002', 'text-davinci-002'), ('text-davinci-edit-001', 'text-davinci-edit-001'), ('code-search-babbage-text-001', 'code-search-babbage-text-001'), ('tts-1-hd-1106', 'tts-1-hd-1106'), ('ada', 'ada'), ('gpt-3.5-turbo-0613', 'gpt-3.5-turbo-0613'), ('text-ada-001', 'text-ada-001'), ('ada-similarity', 'ada-similarity'), ('code-search-ada-code-001', 'code-search-ada-code-001'), ('text-similarity-ada-001', 'text-similarity-ada-001'), ('gpt-4-0613', 'gpt-4-0613'), ('canary-whisper', 'canary-whisper'), ('gpt-3.5-turbo', 'gpt-3.5-turbo'), ('whisper-1', 'whisper-1'), ('text-search-curie-doc-001', 'text-search-curie-doc-001'), ('text-davinci-003', 'text-davinci-003'), ('text-curie-001', 'text-curie-001'), ('curie', 'curie'), ('canary-tts', 'canary-tts'), ('tts-1', 'tts-1'), ('davinci', 'davinci'), ('gpt-3.5-turbo-1106', 'gpt-3.5-turbo-1106'), ('gpt-3.5-turbo-0301', 'gpt-3.5-turbo-0301'), ('dall-e-2', 'dall-e-2'), ('gpt-3.5-turbo-16k-0613', 'gpt-3.5-turbo-16k-0613'), ('tts-1-1106', 'tts-1-1106'), ('dall-e-3', 'dall-e-3'), ('gpt-3.5-turbo-instruct-0914', 'gpt-3.5-turbo-instruct-0914'), ('gpt-3.5-turbo-instruct', 'gpt-3.5-turbo-instruct'), ('gpt-3.5-turbo-16k', 'gpt-3.5-turbo-16k')], default='gpt-3.5-turbo-0613', help_text='Model name to use.', max_length=100, null=True)),
                ('n', models.IntegerField(blank=True, default=1, help_text='Number of chat completions to generate for each prompt.', null=True)),
                ('openai_api_base', models.CharField(blank=True, help_text='Base URL path for API requests, leave blank if not using a proxy or service emulator.', max_length=200, null=True)),
                ('openai_api_key', models.CharField(blank=True, help_text='API key for OpenAI, automatically inferred from env var OPENAI_API_KEY if not provided.', max_length=200, null=True)),
                ('openai_organization', models.CharField(blank=True, default='', help_text='Organization ID for OpenAI, automatically inferred from env var OPENAI_ORG_ID if not provided.', max_length=200, null=True)),
                ('openai_proxy', models.CharField(blank=True, default='', help_text='Proxy settings for OpenAI API.', max_length=200, null=True)),
                ('request_timeout', models.FloatField(blank=True, help_text='Timeout for requests to OpenAI completion API. Can be float, httpx.Timeout or None.', null=True)),
                ('streaming', models.BooleanField(default=False, help_text='Whether to stream the results or not.')),
                ('tags', models.JSONField(blank=True, help_text='Tags to add to the run trace.', null=True)),
                ('temperature', models.FloatField(blank=True, default=0.7, help_text='Sampling temperature to use.', null=True)),
                ('tiktoken_model_name', models.CharField(blank=True, help_text='Model name to pass to tiktoken. Use a different model name here in special cases.', max_length=100, null=True)),
                ('verbose', models.BooleanField(blank=True, default=False, help_text='Whether to print out response text.', null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('owner', models.ForeignKey(on_delete=django.db.models.deletion.RESTRICT, related_name='chat_models', to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'ordering': ['created_at'],
            },
        ),
        migrations.CreateModel(
            name='ChatPromptTemplate',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('system_prompt', models.TextField(blank=True, default='\n\nAlways assist with care, respect, and truth. Respond with utmost utility yet securely. Avoid harmful, unethical, prejudiced, or negative content. Ensure replies promote fairness and positivity.', help_text='System message prompt template', null=True)),
                ('human_prompt', models.TextField(default='\nClassify the text into neutral, negative or positive.\nText: I think the vacation is okay.\nSentiment\n', help_text='Human message prompt template.')),
                ('document_prompt', models.TextField(blank=True, help_text='Human message prompt template.', null=True)),
                ('ai_prompt', models.TextField(blank=True, help_text='\tAI message prompt template.', null=True)),
                ('ai_response', models.TextField(blank=True, help_text='\tAI message response template.', null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('owner', models.ForeignKey(on_delete=django.db.models.deletion.RESTRICT, to=settings.AUTH_USER_MODEL)),
            ],
        ),
        migrations.CreateModel(
            name='LLMServiceKeys',
            fields=[
                ('id', models.UUIDField(default=uuid.uuid4, editable=False, primary_key=True, serialize=False)),
                ('name', models.CharField(max_length=100)),
                ('api_key', models.CharField(blank=True, max_length=100, null=True)),
                ('api_key_redacted', models.CharField(max_length=12)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('user', models.ForeignKey(on_delete=django.db.models.deletion.RESTRICT, to=settings.AUTH_USER_MODEL)),
            ],
        ),
        migrations.CreateModel(
            name='QueryVectorDB',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('document_location', models.TextField()),
                ('embedding_function', models.TextField(default='OpenAIEmbeddings')),
                ('node_id', models.TextField(default='1')),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('user', models.ForeignKey(on_delete=django.db.models.deletion.RESTRICT, to=settings.AUTH_USER_MODEL)),
            ],
        ),
        migrations.CreateModel(
            name='QueryChatModel',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('document_prompt', models.TextField(blank=True, null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('api_key', models.ForeignKey(null=True, on_delete=django.db.models.deletion.CASCADE, to='node_graph.llmservicekeys', verbose_name='llm service api key ')),
                ('chat_model', models.OneToOneField(auto_created=True, on_delete=django.db.models.deletion.RESTRICT, to='node_graph.chatopenai', verbose_name='ai chat model')),
                ('chat_prompt', models.OneToOneField(on_delete=django.db.models.deletion.RESTRICT, to='node_graph.chatprompttemplate', verbose_name='ai chat prompt')),
                ('user', models.ForeignKey(on_delete=django.db.models.deletion.RESTRICT, to=settings.AUTH_USER_MODEL)),
            ],
        ),
        migrations.CreateModel(
            name='NodeGraph',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('file_path', models.FileField(max_length=300, upload_to=node_graph.models.node_graph.user_directory_path)),
                ('label', models.CharField(max_length=70)),
                ('description', models.TextField(blank=True, null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('user', models.ForeignKey(on_delete=django.db.models.deletion.RESTRICT, to=settings.AUTH_USER_MODEL)),
            ],
        ),
    ]
